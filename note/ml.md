# 机器学习

## 概念理解：  

机器学习是对依据经验提升自身性能或丰富自身知识的各种算法和系统的系统性研究。
机器学习所关注的问题是使用正确的特征来构建正确的模型，以完成既定的任务。（任务，模型，特征）
模型赋予机器学习领域以多样性，而特征和任务则为其带来某种程度的一致性。

常见的分类模型有逻辑回归（LR）、朴素贝叶斯、SVM、GBDT和随机森林（RandomForest）、FFM 等  

LR(Logistic Regression)  

SVM(Support Vector Machine)  

GBDT(Gradient Boosting Decision Tree)  

FM（Factorization Machine） 

FFM（Field-aware Factorization Machine）  

标称型数据（类别）：一般在有限的数据中取，而且只存在‘是’和‘否’两种不同的结果（一般用于分类）  
数值型数据：可以在无限的数据中取，而且数值比较具体化，例如4.02,6.23这种值（一般用于回归分析）  


系统性能体现在是否能真正达到目标期望，但存在过拟合问题，可能在某一方面相同问题上表现优异而相似问题上则表现糟糕，因此要考虑系统的推广性，适应性，个性化。



## 机器学习分类：  


+ 1. 监督学习  

有目标期望的学习  

  - 1) 分类  
    目标变量是离散型，如是/否、1/2/3、A/B/C或者红/黄/黑等
    常用分类器算法：
    k-近邻算法、朴素贝叶斯算法、支持向量机、决策树  

  - 2) 回归  
    目标变量是连续型的数值，如0.0～100.00、999～999或者+∞～∞等
    常用回归算法：
    线性回归、局部加权线性回归、Ridge 回归、Lasso 最小回归系数估计  


+ 2. 无监督学习  

无目标期望的学习

  - 1）聚类  
    自分类
    常用算法：
    K-均值（K-mean）、DBSCAN 

  - 2）密度估计
    估计数据与每个分组的相似程度
    常用算法：
    最大期望算法、Parzen窗设计  

另外，还可以根据模型的输出是否含有目标变量来划分模型，如果有则称其为预测性模型，否则称其为描述性模型。

## 机器学习方法论：   

+ 1. 理解数据  

    - 数据类型，离散型或连续型  
    - 数据缺陷，是否缺失等  
    - 数据噪声，是否存在干扰数据  

+ 2. 一般从训练集中拿出一定比例数据做测试，避免真实数据过拟合影响准确率。抽取的方法为了避免运气不好，常使用交叉验证（cross validation）。交叉验证：对数据集中的数据分块，对训练集数据和测试集数据轮流交互验证，让每一部分数据都可以作为测试数据，最后对测试集性能取平均值。交叉验证主要用于有监督数据。

## 机器学习的步骤：

+ 1. 收集数据  
+ 2. 存储数据  
+ 3. 分析数据（人工和自动化）
+ 4. 训练算法--模型（无监督学习不需要训练）
+ 5. 测试算法
+ 6. 使用算法


## 术语：

损失函数或代价函数：用来验证并作为回归函数的目标函数，越逼近拟合效果越好。即代价函数值越小越好。



